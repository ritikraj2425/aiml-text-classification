{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "ZT99hxqY4-CK"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import re\n",
        "import emoji\n",
        "\n",
        "df = pd.read_csv('./datasets/english/davidson.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "X6mg7qam6KOV"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>label</th>\n",
              "      <th>clean_text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>!!! RT @mayasolovely: As a woman you shouldn't...</td>\n",
              "      <td>normal</td>\n",
              "      <td>rt as a woman you shouldnt complain about clea...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>!!!!! RT @mleew17: boy dats cold...tyga dwn ba...</td>\n",
              "      <td>offensive</td>\n",
              "      <td>rt boy dats coldtyga dwn bad for cuffin dat ho...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>!!!!!!! RT @UrKindOfBrand Dawg!!!! RT @80sbaby...</td>\n",
              "      <td>offensive</td>\n",
              "      <td>rt dawg rt you ever fuck a bitch and she start...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>!!!!!!!!! RT @C_G_Anderson: @viva_based she lo...</td>\n",
              "      <td>offensive</td>\n",
              "      <td>rt she look like a tranny</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>!!!!!!!!!!!!! RT @ShenikaRoberts: The shit you...</td>\n",
              "      <td>offensive</td>\n",
              "      <td>rt the shit you hear about me might be true or...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                text      label  \\\n",
              "0  !!! RT @mayasolovely: As a woman you shouldn't...     normal   \n",
              "1  !!!!! RT @mleew17: boy dats cold...tyga dwn ba...  offensive   \n",
              "2  !!!!!!! RT @UrKindOfBrand Dawg!!!! RT @80sbaby...  offensive   \n",
              "3  !!!!!!!!! RT @C_G_Anderson: @viva_based she lo...  offensive   \n",
              "4  !!!!!!!!!!!!! RT @ShenikaRoberts: The shit you...  offensive   \n",
              "\n",
              "                                          clean_text  \n",
              "0  rt as a woman you shouldnt complain about clea...  \n",
              "1  rt boy dats coldtyga dwn bad for cuffin dat ho...  \n",
              "2  rt dawg rt you ever fuck a bitch and she start...  \n",
              "3                          rt she look like a tranny  \n",
              "4  rt the shit you hear about me might be true or...  "
            ]
          },
          "execution_count": 41,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df = df[['tweet', 'class']]\n",
        "\n",
        "df = df.rename(columns={'tweet': 'text', 'class': 'label'})\n",
        "\n",
        "\n",
        "label_map = {0: 'hate', 1: 'offensive', 2: 'normal'}\n",
        "df['label'] = df['label'].map(label_map)\n",
        "\n",
        "\n",
        "def clean_text(text):\n",
        "    text = str(text).lower()\n",
        "    text = re.sub(r'@\\w+', '', text) #Removes @mentions, like @elonmusk\n",
        "    text = re.sub(r'http\\S+|www\\S+', '', text) #Removes URLs, e.g. https://example.com or www.google.com\n",
        "    text = re.sub(r'[^a-z\\s]', '', text) #Removes everything except alphabets and spaces\n",
        "    text = re.sub(r'\\s+', ' ', text).strip() #Collapses multiple spaces into one\n",
        "    text = emoji.replace_emoji(text, replace='') #Removes emojis explicitly, using the emoji library\n",
        "    return text\n",
        "\n",
        "\n",
        "df['clean_text'] = df['text'].apply(clean_text)\n",
        "\n",
        "\n",
        "df = df[df['clean_text'].str.strip() != '']\n",
        "\n",
        "\n",
        "df.to_csv(\"./datasets/english_preprocessed/davidson_preprocessed.csv\", index=False)\n",
        "\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(24781, 3)\n",
            "label\n",
            "offensive    19189\n",
            "normal        4162\n",
            "hate          1430\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "print(df.shape)\n",
        "print(df['label'].value_counts())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g7UvLXy6daX4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "before dropping null\n",
            "(20148, 2)\n",
            "after dropping null\n",
            "(20148, 2)\n"
          ]
        }
      ],
      "source": [
        "import json\n",
        "import pandas as pd\n",
        "import re, emoji\n",
        "from collections import Counter\n",
        "\n",
        "\n",
        "with open(\"./datasets/english/hatexplaindataset.json\", 'r') as f:\n",
        "    data = json.load(f)\n",
        "\n",
        "records = []\n",
        "for post_id, post_data in data.items():\n",
        "    tokens = post_data.get('post_tokens', [])\n",
        "    text = \" \".join(tokens)\n",
        "\n",
        "\n",
        "    labels = [ann.get('label') for ann in post_data.get('annotators', []) if 'label' in ann]\n",
        "    label = Counter(labels).most_common(1)[0][0] if labels else None\n",
        "    records.append({\n",
        "        \"text\": text,\n",
        "        \"label\": label\n",
        "    })\n",
        "\n",
        "df = pd.DataFrame(records)\n",
        "print(\"before dropping null\")\n",
        "print(df.shape)\n",
        "\n",
        "df = df.dropna(subset=['label'])\n",
        "print(\"after dropping null\")\n",
        "print(df.shape)\n",
        "\n",
        "label_map = {\n",
        "    'hatespeech': 'hate',\n",
        "    'offensive': 'offensive',\n",
        "    'normal': 'normal'\n",
        "}\n",
        "df['label'] = df['label'].map(label_map)\n",
        "\n",
        "\n",
        "def clean_text(text):\n",
        "    text = str(text).lower()\n",
        "    text = re.sub(r'@\\w+', '', text)\n",
        "    text = re.sub(r'http\\S+|www\\S+', '', text)\n",
        "    text = re.sub(r'[^a-z\\s]', '', text)\n",
        "    text = re.sub(r'\\s+', ' ', text).strip()\n",
        "    text = emoji.replace_emoji(text, replace='')\n",
        "    return text\n",
        "\n",
        "df['clean_text'] = df['text'].apply(clean_text)\n",
        "df = df[df['clean_text'].str.strip() != '']\n",
        "\n",
        "\n",
        "df = df[['text', 'label', 'clean_text']]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "Lek73mL1dnW6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                                                text   label  \\\n",
            "0  i dont think im getting my baby them white 9 h...  normal   \n",
            "1  we cannot continue calling ourselves feminists...  normal   \n",
            "2                      nawt yall niggers ignoring me  normal   \n",
            "3  <user> i am bit confused coz chinese ppl can n...    hate   \n",
            "4  this bitch in whataburger eating a burger with...    hate   \n",
            "\n",
            "                                          clean_text  \n",
            "0  i dont think im getting my baby them white he ...  \n",
            "1  we cannot continue calling ourselves feminists...  \n",
            "2                      nawt yall niggers ignoring me  \n",
            "3  user i am bit confused coz chinese ppl can not...  \n",
            "4  this bitch in whataburger eating a burger with...  \n"
          ]
        }
      ],
      "source": [
        "df.to_csv(\"./datasets/english_preprocessed/english_hatexplain_preprocessed.csv\", index=False)\n",
        "print(df.head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(20148, 3)\n",
            "label\n",
            "normal       8153\n",
            "hate         6234\n",
            "offensive    5761\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "print(df.shape)\n",
        "print(df['label'].value_counts())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "id": "vkiAO9Og6Yut"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(41144, 13)\n",
            "label\n",
            "hate       22175\n",
            "nothate    18969\n",
            "Name: count, dtype: int64\n",
            "                                                text label  \\\n",
            "0                                dalits are lowlives  hate   \n",
            "1             gay people are a burden to our society  hate   \n",
            "2                              Arabs are not welcome  hate   \n",
            "3  I'm not saying we should actually eliminate he...  hate   \n",
            "4                       bananas are for black people  hate   \n",
            "\n",
            "                                          clean_text  \n",
            "0                                dalits are lowlives  \n",
            "1             gay people are a burden to our society  \n",
            "2                              arabs are not welcome  \n",
            "3  im not saying we should actually eliminate hee...  \n",
            "4                       bananas are for black people  \n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import re, emoji\n",
        "\n",
        "\n",
        "df = pd.read_csv(\"./datasets/english/Dynamically_Generated_Hate_Dataset_v0.2.3.csv\")\n",
        "print(df.shape)\n",
        "print(df['label'].value_counts())\n",
        "\n",
        "\n",
        "df = df[['text', 'label']].copy()\n",
        "\n",
        "\n",
        "def clean_text(text):\n",
        "    text = str(text).lower()\n",
        "    text = re.sub(r'@\\w+', '', text)\n",
        "    text = re.sub(r'http\\S+|www\\S+', '', text)\n",
        "    text = re.sub(r'[^a-z\\s]', '', text)\n",
        "    text = emoji.replace_emoji(text, replace='')\n",
        "    text = re.sub(r'\\s+', ' ', text).strip()\n",
        "    return text\n",
        "\n",
        "df['clean_text'] = df['text'].apply(clean_text)\n",
        "\n",
        "\n",
        "label_map = {'hate': 'hate', 'nothate': 'normal'}\n",
        "df['label'] = df['label'].str.lower().map(label_map)\n",
        "\n",
        "\n",
        "df = df.dropna(subset=['label', 'clean_text'])\n",
        "df = df[df['clean_text'].str.strip() != '']\n",
        "\n",
        "\n",
        "df = df[['text', 'label', 'clean_text']]\n",
        "\n",
        "\n",
        "df.to_csv(\"./datasets/english_preprocessed/Preprocessed_Dynamically_Generated_Hate_Dataset_v0.csv\", index=False)\n",
        "\n",
        "print(df.head())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Davidson dataset shape: (24781, 3)\n",
            "HateXplain dataset shape: (20148, 3)\n",
            "Dynamic dataset shape: (41144, 3)\n",
            "\n",
            "==================================================\n",
            "Merged Dataset Info:\n",
            "==================================================\n",
            "Total shape: (86073, 3)\n",
            "\n",
            "Label distribution:\n",
            "label\n",
            "normal       31284\n",
            "hate         29839\n",
            "offensive    24950\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Label percentages:\n",
            "label\n",
            "normal       36.345892\n",
            "hate         34.667085\n",
            "offensive    28.987023\n",
            "Name: proportion, dtype: float64\n",
            "\n",
            "✅ Merged dataset saved as 'all_english_data.csv'\n",
            "\n",
            "First few rows:\n",
            "                                                text      label  \\\n",
            "0  !!! RT @mayasolovely: As a woman you shouldn't...     normal   \n",
            "1  !!!!! RT @mleew17: boy dats cold...tyga dwn ba...  offensive   \n",
            "2  !!!!!!! RT @UrKindOfBrand Dawg!!!! RT @80sbaby...  offensive   \n",
            "3  !!!!!!!!! RT @C_G_Anderson: @viva_based she lo...  offensive   \n",
            "4  !!!!!!!!!!!!! RT @ShenikaRoberts: The shit you...  offensive   \n",
            "\n",
            "                                          clean_text  \n",
            "0  rt as a woman you shouldnt complain about clea...  \n",
            "1  rt boy dats coldtyga dwn bad for cuffin dat ho...  \n",
            "2  rt dawg rt you ever fuck a bitch and she start...  \n",
            "3                          rt she look like a tranny  \n",
            "4  rt the shit you hear about me might be true or...  \n"
          ]
        }
      ],
      "source": [
        "\n",
        "df_davidson = pd.read_csv(\"./datasets/english_preprocessed/davidson_preprocessed.csv\")\n",
        "df_hatexplain = pd.read_csv(\"./datasets/english_preprocessed/english_hatexplain_preprocessed.csv\")\n",
        "df_dynamic = pd.read_csv(\"./datasets/english_preprocessed/Preprocessed_Dynamically_Generated_Hate_Dataset_v0.csv\")\n",
        "\n",
        "print(\"Davidson dataset shape:\", df_davidson.shape)\n",
        "print(\"HateXplain dataset shape:\", df_hatexplain.shape)\n",
        "print(\"Dynamic dataset shape:\", df_dynamic.shape)\n",
        "\n",
        "all_english_data = pd.concat([df_davidson, df_hatexplain, df_dynamic], ignore_index=True)\n",
        "\n",
        "print(\"\\n\" + \"=\"*50)\n",
        "print(\"Merged Dataset Info:\")\n",
        "print(\"=\"*50)\n",
        "print(f\"Total shape: {all_english_data.shape}\")\n",
        "print(f\"\\nLabel distribution:\")\n",
        "print(all_english_data['label'].value_counts())\n",
        "print(f\"\\nLabel percentages:\")\n",
        "print(all_english_data['label'].value_counts(normalize=True) * 100)\n",
        "\n",
        "all_english_data.to_csv(\"./datasets/english_preprocessed/all_english_data.csv\", index=False)\n",
        "print(f\"\\n✅ Merged dataset saved as 'all_english_data.csv'\")\n",
        "print(f\"\\nFirst few rows:\")\n",
        "print(all_english_data.head())\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "gpuType": "V5E1",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "data-mining",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.14"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
