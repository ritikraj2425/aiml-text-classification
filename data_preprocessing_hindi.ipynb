{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ba4b53da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in /Users/ritikraj/text_classification_aiml_project/.venv/lib/python3.14/site-packages (2.3.3)\n",
      "Requirement already satisfied: numpy in /Users/ritikraj/text_classification_aiml_project/.venv/lib/python3.14/site-packages (2.3.4)\n",
      "Requirement already satisfied: scikit-learn in /Users/ritikraj/text_classification_aiml_project/.venv/lib/python3.14/site-packages (1.7.2)\n",
      "Requirement already satisfied: torch in /Users/ritikraj/text_classification_aiml_project/.venv/lib/python3.14/site-packages (2.9.1)\n",
      "Requirement already satisfied: transformers in /Users/ritikraj/text_classification_aiml_project/.venv/lib/python3.14/site-packages (4.57.1)\n",
      "Requirement already satisfied: matplotlib in /Users/ritikraj/text_classification_aiml_project/.venv/lib/python3.14/site-packages (3.10.7)\n",
      "Collecting seaborn\n",
      "  Downloading seaborn-0.13.2-py3-none-any.whl.metadata (5.4 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/ritikraj/text_classification_aiml_project/.venv/lib/python3.14/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/ritikraj/text_classification_aiml_project/.venv/lib/python3.14/site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /Users/ritikraj/text_classification_aiml_project/.venv/lib/python3.14/site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: scipy>=1.8.0 in /Users/ritikraj/text_classification_aiml_project/.venv/lib/python3.14/site-packages (from scikit-learn) (1.16.3)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /Users/ritikraj/text_classification_aiml_project/.venv/lib/python3.14/site-packages (from scikit-learn) (1.5.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /Users/ritikraj/text_classification_aiml_project/.venv/lib/python3.14/site-packages (from scikit-learn) (3.6.0)\n",
      "Requirement already satisfied: filelock in /Users/ritikraj/text_classification_aiml_project/.venv/lib/python3.14/site-packages (from torch) (3.20.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /Users/ritikraj/text_classification_aiml_project/.venv/lib/python3.14/site-packages (from torch) (4.15.0)\n",
      "Requirement already satisfied: setuptools in /Users/ritikraj/text_classification_aiml_project/.venv/lib/python3.14/site-packages (from torch) (80.9.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /Users/ritikraj/text_classification_aiml_project/.venv/lib/python3.14/site-packages (from torch) (1.14.0)\n",
      "Requirement already satisfied: networkx>=2.5.1 in /Users/ritikraj/text_classification_aiml_project/.venv/lib/python3.14/site-packages (from torch) (3.5)\n",
      "Requirement already satisfied: jinja2 in /Users/ritikraj/text_classification_aiml_project/.venv/lib/python3.14/site-packages (from torch) (3.1.6)\n",
      "Requirement already satisfied: fsspec>=0.8.5 in /Users/ritikraj/text_classification_aiml_project/.venv/lib/python3.14/site-packages (from torch) (2025.10.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in /Users/ritikraj/text_classification_aiml_project/.venv/lib/python3.14/site-packages (from transformers) (0.36.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/ritikraj/text_classification_aiml_project/.venv/lib/python3.14/site-packages (from transformers) (25.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Users/ritikraj/text_classification_aiml_project/.venv/lib/python3.14/site-packages (from transformers) (6.0.3)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /Users/ritikraj/text_classification_aiml_project/.venv/lib/python3.14/site-packages (from transformers) (2025.11.3)\n",
      "Requirement already satisfied: requests in /Users/ritikraj/text_classification_aiml_project/.venv/lib/python3.14/site-packages (from transformers) (2.32.5)\n",
      "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /Users/ritikraj/text_classification_aiml_project/.venv/lib/python3.14/site-packages (from transformers) (0.22.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /Users/ritikraj/text_classification_aiml_project/.venv/lib/python3.14/site-packages (from transformers) (0.6.2)\n",
      "Requirement already satisfied: tqdm>=4.27 in /Users/ritikraj/text_classification_aiml_project/.venv/lib/python3.14/site-packages (from transformers) (4.67.1)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /Users/ritikraj/text_classification_aiml_project/.venv/lib/python3.14/site-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (1.2.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /Users/ritikraj/text_classification_aiml_project/.venv/lib/python3.14/site-packages (from matplotlib) (1.3.3)\n",
      "Requirement already satisfied: cycler>=0.10 in /Users/ritikraj/text_classification_aiml_project/.venv/lib/python3.14/site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /Users/ritikraj/text_classification_aiml_project/.venv/lib/python3.14/site-packages (from matplotlib) (4.61.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /Users/ritikraj/text_classification_aiml_project/.venv/lib/python3.14/site-packages (from matplotlib) (1.4.9)\n",
      "Requirement already satisfied: pillow>=8 in /Users/ritikraj/text_classification_aiml_project/.venv/lib/python3.14/site-packages (from matplotlib) (12.0.0)\n",
      "Requirement already satisfied: pyparsing>=3 in /Users/ritikraj/text_classification_aiml_project/.venv/lib/python3.14/site-packages (from matplotlib) (3.2.5)\n",
      "Requirement already satisfied: six>=1.5 in /Users/ritikraj/text_classification_aiml_project/.venv/lib/python3.14/site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /Users/ritikraj/text_classification_aiml_project/.venv/lib/python3.14/site-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/ritikraj/text_classification_aiml_project/.venv/lib/python3.14/site-packages (from jinja2->torch) (3.0.3)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /Users/ritikraj/text_classification_aiml_project/.venv/lib/python3.14/site-packages (from requests->transformers) (3.4.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/ritikraj/text_classification_aiml_project/.venv/lib/python3.14/site-packages (from requests->transformers) (3.11)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/ritikraj/text_classification_aiml_project/.venv/lib/python3.14/site-packages (from requests->transformers) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/ritikraj/text_classification_aiml_project/.venv/lib/python3.14/site-packages (from requests->transformers) (2025.11.12)\n",
      "Downloading seaborn-0.13.2-py3-none-any.whl (294 kB)\n",
      "Installing collected packages: seaborn\n",
      "Successfully installed seaborn-0.13.2\n"
     ]
    }
   ],
   "source": [
    "!pip install pandas numpy scikit-learn torch transformers matplotlib seaborn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "713b12d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ritikraj/text_classification_aiml_project/.venv/lib/python3.14/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset shape: (5983, 5)\n",
      "\n",
      "First few rows:\n",
      "         text_id                                               text task_1  \\\n",
      "0  hasoc_hi_5061  वक्त, इन्सान और इंग्लैंड का मौसम आपको कभी भी ध...    NOT   \n",
      "1  hasoc_hi_2090  #कांग्रेस के इस #कमीने की #करतूत को देखिए देश ...    HOF   \n",
      "2  hasoc_hi_2960  पाकिस्तान को फेकना था फेका गया। जो हार कर भी द...    HOF   \n",
      "3   hasoc_hi_864  जो शब्द तूम आज किसी और औरत के लिए यूज कर रहे व...    NOT   \n",
      "4    hasoc_hi_54  नेता जी हम समाजवादी सिपाही हमेशा आपके साथ है आ...    NOT   \n",
      "\n",
      "  task_2 task_3  \n",
      "0   NONE   NONE  \n",
      "1   OFFN    TIN  \n",
      "2   OFFN    TIN  \n",
      "3   NONE   NONE  \n",
      "4   NONE   NONE  \n",
      "\n",
      "Dataset columns: ['text_id', 'text', 'task_1', 'task_2', 'task_3']\n",
      "\n",
      "Hindi dataset label distribution:\n",
      "label\n",
      "normal       2909\n",
      "hate         2201\n",
      "offensive     873\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Number of unique labels: 3\n",
      "Unique labels: ['normal' 'offensive' 'hate']\n",
      "\n",
      "Rows with empty text: 2\n",
      "\n",
      "Shuffling the dataset...\n",
      "Final dataset size: 5981\n",
      "\n",
      "Unique labels in dataset: ['hate', 'normal', 'offensive']\n",
      "Label mapping: {'hate': 0, 'normal': 1, 'offensive': 2}\n",
      "\n",
      "Final label distribution:\n",
      "label\n",
      "normal       2907\n",
      "hate         2201\n",
      "offensive     873\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Encoded label distribution:\n",
      "label_encoded\n",
      "1    2907\n",
      "0    2201\n",
      "2     873\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import shuffle\n",
    "import torch\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    AutoModelForSequenceClassification,\n",
    "    TrainingArguments,\n",
    "    Trainer,\n",
    "    EarlyStoppingCallback\n",
    ")\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support, classification_report\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Load your Hindi datasets\n",
    "dataset1 = pd.read_csv('datasets/hindi/hasoc_hindi_dataset/hasoc2019_hi_test_gold_2919.tsv', sep='\\t')  # Adjust separator if needed\n",
    "dataset2 = pd.read_csv('datasets/hindi/hasoc_hindi_dataset/hindi_dataset.tsv', sep='\\t')  # Adjust separator if needed\n",
    "\n",
    "# Combine datasets\n",
    "df_hindi = pd.concat([dataset1, dataset2], ignore_index=True)\n",
    "\n",
    "print(\"Dataset shape:\", df_hindi.shape)\n",
    "print(\"\\nFirst few rows:\")\n",
    "print(df_hindi.head())\n",
    "\n",
    "# Clean column names (remove extra spaces)\n",
    "df_hindi.columns = df_hindi.columns.str.strip()\n",
    "\n",
    "# Let's check the columns\n",
    "print(\"\\nDataset columns:\", df_hindi.columns.tolist())\n",
    "\n",
    "# Define mapping from task labels to our classes\n",
    "def map_to_classes(row):\n",
    "    \"\"\"\n",
    "    Map from task_1 and task_2 labels to ['hate', 'normal', 'offensive']\n",
    "    \n",
    "    Based on your examples:\n",
    "    - NOT + NONE → normal\n",
    "    - HOF + PRFN → hate (profane)\n",
    "    - HOF + OFFN → offensive\n",
    "    - HOF + NONE → hate (default for HOF without specific task_2)\n",
    "    \"\"\"\n",
    "    task1 = str(row['task_1']).strip().upper() if 'task_1' in row else 'NOT'\n",
    "    task2 = str(row['task_2']).strip().upper() if 'task_2' in row else 'NONE'\n",
    "    \n",
    "    if task1 == 'NOT':\n",
    "        return 'normal'\n",
    "    elif task1 == 'HOF':\n",
    "        if task2 == 'PRFN':\n",
    "            return 'hate'\n",
    "        elif task2 == 'OFFN':\n",
    "            return 'offensive'\n",
    "        else:  # HOF with NONE or other\n",
    "            return 'hate'  # Default to hate for HOF\n",
    "    else:\n",
    "        # Default for any other cases\n",
    "        return 'normal'\n",
    "\n",
    "# Apply mapping\n",
    "df_hindi['label'] = df_hindi.apply(map_to_classes, axis=1)\n",
    "\n",
    "# Clean text column (remove URLs, special characters, etc.)\n",
    "def clean_hindi_text(text):\n",
    "    if pd.isna(text):\n",
    "        return \"\"\n",
    "    \n",
    "    text = str(text)\n",
    "    \n",
    "    # Remove URLs\n",
    "    text = re.sub(r'http\\S+|www\\S+|https\\S+', '', text, flags=re.MULTILINE)\n",
    "    \n",
    "    # Remove mentions and hashtags (keep the text after #)\n",
    "    text = re.sub(r'@\\w+', '', text)\n",
    "    text = re.sub(r'#', '', text)\n",
    "    \n",
    "    # Remove RT (retweet)\n",
    "    text = re.sub(r'RT\\s+', '', text)\n",
    "    \n",
    "    # Remove extra whitespace\n",
    "    text = ' '.join(text.split())\n",
    "    \n",
    "    return text\n",
    "\n",
    "import re\n",
    "\n",
    "# Apply cleaning\n",
    "df_hindi['clean_text'] = df_hindi['text'].apply(clean_hindi_text)\n",
    "\n",
    "# Check label distribution\n",
    "print(\"\\nHindi dataset label distribution:\")\n",
    "label_counts = df_hindi['label'].value_counts()\n",
    "print(label_counts)\n",
    "\n",
    "print(f\"\\nNumber of unique labels: {df_hindi['label'].nunique()}\")\n",
    "print(f\"Unique labels: {df_hindi['label'].unique()}\")\n",
    "\n",
    "# Check for empty texts\n",
    "empty_texts = df_hindi[df_hindi['clean_text'].str.strip() == '']\n",
    "print(f\"\\nRows with empty text: {len(empty_texts)}\")\n",
    "\n",
    "# Remove empty texts if any\n",
    "df_hindi = df_hindi[df_hindi['clean_text'].str.strip() != '']\n",
    "\n",
    "# Shuffle the dataset\n",
    "print(\"\\nShuffling the dataset...\")\n",
    "df_shuffled = shuffle(df_hindi, random_state=42).reset_index(drop=True)\n",
    "\n",
    "print(f\"Final dataset size: {len(df_shuffled)}\")\n",
    "\n",
    "# Map labels to numerical values\n",
    "unique_labels = sorted(df_shuffled['label'].unique())\n",
    "print(f\"\\nUnique labels in dataset: {unique_labels}\")\n",
    "\n",
    "label_map = {label: idx for idx, label in enumerate(unique_labels)}\n",
    "reverse_label_map = {idx: label for label, idx in label_map.items()}\n",
    "\n",
    "print(f\"Label mapping: {label_map}\")\n",
    "\n",
    "df_shuffled['label_encoded'] = df_shuffled['label'].map(label_map)\n",
    "\n",
    "# Check distribution\n",
    "print(\"\\nFinal label distribution:\")\n",
    "print(df_shuffled['label'].value_counts())\n",
    "print(f\"\\nEncoded label distribution:\")\n",
    "print(df_shuffled['label_encoded'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4b8141c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_shuffled.to_csv('hindi_processed_data.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a30d47e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text_id</th>\n",
       "      <th>text</th>\n",
       "      <th>task_1</th>\n",
       "      <th>task_2</th>\n",
       "      <th>task_3</th>\n",
       "      <th>label</th>\n",
       "      <th>clean_text</th>\n",
       "      <th>label_encoded</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>hasoc_hi_3825</td>\n",
       "      <td>आज ये बात पक्की हो गई कि #भडवा कलर sorry #भगवा...</td>\n",
       "      <td>NOT</td>\n",
       "      <td>NONE</td>\n",
       "      <td>NONE</td>\n",
       "      <td>normal</td>\n",
       "      <td>आज ये बात पक्की हो गई कि भडवा कलर sorry भगवा क...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>hasoc_hi_5196</td>\n",
       "      <td>My Speech today on President Address Debate in...</td>\n",
       "      <td>NOT</td>\n",
       "      <td>NONE</td>\n",
       "      <td>NONE</td>\n",
       "      <td>normal</td>\n",
       "      <td>My Speech today on President Address Debate in...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>hasoc_hi_3655</td>\n",
       "      <td>नहीं माने राहुल: नए अध्यक्ष की तलाश शुरू, दो द...</td>\n",
       "      <td>NOT</td>\n",
       "      <td>NONE</td>\n",
       "      <td>NONE</td>\n",
       "      <td>normal</td>\n",
       "      <td>नहीं माने राहुल: नए अध्यक्ष की तलाश शुरू, दो द...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>hasoc_hi_895</td>\n",
       "      <td>कश्मीर का नाम सुनते ही आतंकवाद और पत्थरबाज</td>\n",
       "      <td>HOF</td>\n",
       "      <td>OFFN</td>\n",
       "      <td>TIN</td>\n",
       "      <td>offensive</td>\n",
       "      <td>कश्मीर का नाम सुनते ही आतंकवाद और पत्थरबाज</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>hasoc_hi_6627</td>\n",
       "      <td>@KaDevender मोदी जी पागल है जो जल संरक्षण के प...</td>\n",
       "      <td>HOF</td>\n",
       "      <td>PRFN</td>\n",
       "      <td>TIN</td>\n",
       "      <td>hate</td>\n",
       "      <td>मोदी जी पागल है जो जल संरक्षण के पीछे पागल हुए...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         text_id                                               text task_1  \\\n",
       "0  hasoc_hi_3825  आज ये बात पक्की हो गई कि #भडवा कलर sorry #भगवा...    NOT   \n",
       "1  hasoc_hi_5196  My Speech today on President Address Debate in...    NOT   \n",
       "2  hasoc_hi_3655  नहीं माने राहुल: नए अध्यक्ष की तलाश शुरू, दो द...    NOT   \n",
       "3   hasoc_hi_895         कश्मीर का नाम सुनते ही आतंकवाद और पत्थरबाज    HOF   \n",
       "4  hasoc_hi_6627  @KaDevender मोदी जी पागल है जो जल संरक्षण के प...    HOF   \n",
       "\n",
       "  task_2 task_3      label                                         clean_text  \\\n",
       "0   NONE   NONE     normal  आज ये बात पक्की हो गई कि भडवा कलर sorry भगवा क...   \n",
       "1   NONE   NONE     normal  My Speech today on President Address Debate in...   \n",
       "2   NONE   NONE     normal  नहीं माने राहुल: नए अध्यक्ष की तलाश शुरू, दो द...   \n",
       "3   OFFN    TIN  offensive         कश्मीर का नाम सुनते ही आतंकवाद और पत्थरबाज   \n",
       "4   PRFN    TIN       hate  मोदी जी पागल है जो जल संरक्षण के पीछे पागल हुए...   \n",
       "\n",
       "   label_encoded  \n",
       "0              1  \n",
       "1              1  \n",
       "2              1  \n",
       "3              2  \n",
       "4              0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_shuffled.head()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Ritik Env",
   "language": "python",
   "name": "custom_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
